# Backend LLM config
# For deterministic local dev/tests, set USE_LLM_MOCK=1
USE_LLM_MOCK=0
ALLOW_PREVIEW_TESTS=0
OPENAI_API_BASE=
OPENAI_API_KEY=
LLM_MODEL_MINI=openai/gpt-5-mini-2025-08-07
LLM_MODEL_NANO=openai/gpt-5-nano-2025-08-07
LLM_RESPONSE_FORMAT_JSON=1
LLM_PREVIEW_MAX_CHARS=1000
LLM_PREVIEW_MAX_TOKENS=8000

# Enhanced chunking and tagging (ingestion)
ENHANCED_CHUNKING_ENABLED=false
ENHANCED_TAGGING_ENABLED=false
FORMULA_EXTRACTION_ENABLED=false
EXTENDED_CONTEXT_ENABLED=false
CHUNK_LINKING_ENABLED=false

# Semantic splitter defaults
SEM_SPLIT_TAU=0.65
SEM_MIN_TOKENS=60
SEM_MAX_TOKENS=240
SEM_OVERLAP=1
SEM_BATCH_SIZE=
INGEST_PAGE_MAX_CHARS=6000

# Content-aware semantic chunking
SEMANTIC_CHUNK_CONTENT_AWARE=true
SEMANTIC_CHUNK_MIN_TOKENS_CONCEPT=100
SEMANTIC_CHUNK_MAX_TOKENS_CONCEPT=300
SEMANTIC_CHUNK_MIN_TOKENS_DERIVATION=300
SEMANTIC_CHUNK_MAX_TOKENS_DERIVATION=500
SEMANTIC_CHUNK_MIN_TOKENS_EXAMPLE=150
SEMANTIC_CHUNK_MAX_TOKENS_EXAMPLE=400
SEMANTIC_CHUNK_MIN_TOKENS_SUMMARY=50
SEMANTIC_CHUNK_MAX_TOKENS_SUMMARY=150
INGEST_TAGS_PER_CHUNK=6

# Pedagogy role classification
PEDAGOGY_LLM_CLASSIFICATION=false
PEDAGOGY_LLM_CONFIDENCE_THRESHOLD=0.7

# Prompt Registry / Observability
# Active prompt set name (maps to backend/prompts and used for metrics tagging)
PROMPT_SET=baseline
# Enable OpenTelemetry spans (local/dev optional)
OTEL_ENABLE=0

# Mastery tuning
MASTERY_STEP_CORRECT=0.1
MASTERY_STEP_WRONG=-0.05
MASTERY_DECAY_LAMBDA=0.0

# Retrieval tunables (defaults used if unset)
RETRIEVAL_SIM_WEIGHT=0.7
RETRIEVAL_BM25_WEIGHT=0.3
RETRIEVAL_RESOURCE_BOOST=1.0
RETRIEVAL_PAGE_PROXIMITY=false
# Optional pedagogy-aware filtering/boosting
RETRIEVAL_PEDAGOGY_FILTER=false
RETRIEVAL_PEDAGOGY_RELAX_IF_EMPTY=true
# Grounding thresholds (agents will refuse if no chunks pass these)
RAG_MIN_SCORE=0.35
RAG_MIN_SIM=0.30
RAG_MIN_BM25=0.15

# Database
# When running via Docker Compose, use container networking values below.
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=app
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
# If running locally without Docker, prefer host Postgres on 5433 (per dev norms)
# POSTGRES_HOST=localhost
# POSTGRES_PORT=5433

# Dev user for local analytics/doubt logging
TEST_USER_ID=

# Object storage (MinIO)
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin
MINIO_ENDPOINT=minio:9000
MINIO_SECURE=false
MINIO_BUCKET=resources

# Redis / RQ
REDIS_URL=redis://redis:6379/0

# Embeddings
EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBED_VERSION=all-MiniLM-L6-v2-2025-09

# Tutor mastery real-time updates (optional; default off)
TUTOR_MASTERY_REALTIME_UPDATE=false
TUTOR_MASTERY_LEARNING_RATE=0.1
TUTOR_MASTERY_DECAY_FACTOR=0.95
TUTOR_MASTERY_MIN_UPDATE=0.05
TUTOR_MASTERY_MAX_UPDATE=0.3

TUTOR_EXAMPLE_GENERATION_ENABLED=false
TUTOR_EXAMPLE_MIN_RELEVANCE=0.6
TUTOR_EXAMPLE_MIN_CONFIDENCE=0.5
TUTOR_EXAMPLE_CACHE_SIZE=100
TUTOR_EXAMPLE_DEFAULT_CONTEXT=everyday
TUTOR_STUDENT_BACKGROUND=general

# Step-wise rubric (SRL-inspired) â€” off by default
TUTOR_STEPWISE_RUBRIC_ENABLED=false
TUTOR_RL_EXPORT_STEP_SCORES=false
# Step weights (should sum to 1.0; normalized at runtime if not)
TUTOR_STEP_WEIGHT_UNDERSTAND=0.15
TUTOR_STEP_WEIGHT_PEDAGOGY=0.25
TUTOR_STEP_WEIGHT_RETRIEVAL=0.20
TUTOR_STEP_WEIGHT_STRUCTURE=0.20
TUTOR_STEP_WEIGHT_OUTPUT=0.15
TUTOR_STEP_WEIGHT_FORMATIVE=0.05
# Optional: include step-wise in reward aggregation
TUTOR_RL_WEIGHT_STEPWISE=0.0
TUTOR_RL_THRESHOLD_STEPWISE=0.6

# Knowledge Graph extraction and quality controls
KG_ENHANCED_EXTRACTION_ENABLED=false
KG_MIN_CONFIDENCE_DEFINES=0.80
KG_MIN_CONFIDENCE_PREREQUISITE=0.75
KG_MIN_CONFIDENCE_DERIVES=0.75
KG_MIN_CONFIDENCE_EXPLAINS=0.65
KG_MIN_CONFIDENCE_APPLIES_TO=0.65
KG_MIN_CONFIDENCE_EXEMPLIFIES=0.60
KG_MIN_CONFIDENCE_DEFAULT=0.65
KG_SEMANTIC_VALIDATION_ENABLED=true
KG_MIN_SEMANTIC_SIMILARITY=0.30
KG_PRUNE_MODE=moderate
KG_MAX_NODE_DEGREE=50
KG_MIN_RELATIONSHIP_CONFIDENCE=0.5
KG_FUZZY_MATCH_THRESHOLD=0.85

# SRL (Supervised Reinforcement Learning) multi-stage reasoning flow
# Enable SRL mode (experimental; off by default)
TUTOR_SRL_MODE=false
# Planning stage toggle
TUTOR_SRL_PLANNING_ENABLED=true
# Optional self-critique stage
TUTOR_SRL_SELF_CRITIQUE=false
# Future: allow revision loop based on critique
TUTOR_SRL_REVISION_LOOP=false
# Logging for SRL artifacts
TUTOR_SRL_LOG_THINKING=true
TUTOR_SRL_LOG_CRITIQUE=true
# Export SRL reasoning into observation for RL datasets
TUTOR_RL_EXPORT_REASONING=false

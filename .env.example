# Backend LLM config
# For deterministic local dev/tests, set USE_LLM_MOCK=1
USE_LLM_MOCK=0
ALLOW_PREVIEW_TESTS=0
OPENAI_API_BASE=
OPENAI_API_KEY=
LLM_MODEL_MINI=openai/gpt-5-mini-2025-08-07
LLM_MODEL_NANO=openai/gpt-5-nano-2025-08-07
LLM_RESPONSE_FORMAT_JSON=1
LLM_PREVIEW_MAX_CHARS=1000
LLM_PREVIEW_MAX_TOKENS=8000

# Prompt Registry / Observability
# Active prompt set name (maps to backend/prompts and used for metrics tagging)
PROMPT_SET=baseline
# Enable OpenTelemetry spans (local/dev optional)
OTEL_ENABLE=0

# Mastery tuning
MASTERY_STEP_CORRECT=0.1
MASTERY_STEP_WRONG=-0.05
MASTERY_DECAY_LAMBDA=0.0

# Retrieval tunables (defaults used if unset)
RETRIEVAL_SIM_WEIGHT=0.7
RETRIEVAL_BM25_WEIGHT=0.3
RETRIEVAL_RESOURCE_BOOST=1.0
RETRIEVAL_PAGE_PROXIMITY=false
# Grounding thresholds (agents will refuse if no chunks pass these)
RAG_MIN_SCORE=0.35
RAG_MIN_SIM=0.30
RAG_MIN_BM25=0.15

# Database
# When running via Docker Compose, use container networking values below.
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=app
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
# If running locally without Docker, prefer host Postgres on 5433 (per dev norms)
# POSTGRES_HOST=localhost
# POSTGRES_PORT=5433

# Dev user for local analytics/doubt logging
TEST_USER_ID=

# Object storage (MinIO)
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin
MINIO_ENDPOINT=minio:9000
MINIO_SECURE=false
MINIO_BUCKET=resources

# Redis / RQ
REDIS_URL=redis://redis:6379/0

# Embeddings
EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBED_VERSION=all-MiniLM-L6-v2-2025-09
